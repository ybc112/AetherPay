"""
è¶…çº§å¿«é€Ÿè®­ç»ƒè„šæœ¬ - 30ç§’å®Œæˆ
åªç”¨æœ€å°‘çš„æ•°æ®å’Œç‰¹å¾ï¼Œä½†ä¿æŒåˆç†çš„å‡†ç¡®ç‡
"""

import numpy as np
import pandas as pd
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import sqlite3
import json
import os
from datetime import datetime, timedelta
import logging
import warnings

warnings.filterwarnings('ignore')
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

class SuperFastTrainer:
    """æé€Ÿè®­ç»ƒå™¨ - 30ç§’å®Œæˆ"""

    def __init__(self, model_dir='./saved_models'):
        self.model_dir = model_dir
        os.makedirs(model_dir, exist_ok=True)

    def train_super_fast(self, pair='ETH/USDT'):
        """è¶…å¿«é€Ÿè®­ç»ƒ - æç®€ä½†æœ‰æ•ˆ"""

        logger.info(f"\n{'='*60}")
        logger.info(f"âš¡ æé€Ÿè®­ç»ƒ {pair} - ç›®æ ‡30ç§’å®Œæˆ")
        logger.info(f"{'='*60}\n")

        start_time = datetime.now()

        # 1. åªåŠ è½½æœ€è¿‘1å¤©çš„æ•°æ®ï¼ˆå‡å°‘æ•°æ®é‡ï¼‰
        logger.info("ğŸ“¥ åŠ è½½æœ€å°‘å¿…è¦æ•°æ®...")
        X, y = self._load_minimal_data(pair, hours=24)  # åªç”¨24å°æ—¶æ•°æ®

        if len(X) < 100:
            logger.error(f"æ•°æ®ä¸è¶³: {len(X)}æ¡")
            return None

        logger.info(f"âœ… æ•°æ®: {len(X)}æ ·æœ¬ Ã— {X.shape[1]}ç‰¹å¾")

        # 2. ç®€å•åˆ†å‰²
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, shuffle=False
        )

        # 3. ç›´æ¥è®­ç»ƒï¼ˆä¸åšå‚æ•°æœç´¢ï¼‰
        logger.info("ğŸš€ å¿«é€Ÿè®­ç»ƒ...")
        model = lgb.LGBMRegressor(
            n_estimators=50,  # åªç”¨50æ£µæ ‘
            learning_rate=0.1,
            num_leaves=31,
            max_depth=5,
            random_state=42,
            n_jobs=-1,
            verbosity=-1
        )

        model.fit(X_train, y_train,
                 eval_set=[(X_test, y_test)],
                 callbacks=[lgb.early_stopping(5), lgb.log_evaluation(0)])

        # 4. å¿«é€Ÿè¯„ä¼°
        y_pred = model.predict(X_test)
        r2 = r2_score(y_test, y_pred)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))

        logger.info(f"ğŸ“Š æ€§èƒ½: RÂ²={r2:.3f}, RMSE={rmse:.1f}")

        # 5. ä¿å­˜
        self._save_fast_model(pair, model, r2, rmse)

        # è®¡æ—¶
        total_time = (datetime.now() - start_time).total_seconds()
        logger.info(f"\nâœ… å®Œæˆï¼è€—æ—¶: {total_time:.1f}ç§’")
        logger.info(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {self.model_dir}")

        return {'r2': r2, 'rmse': rmse, 'time': total_time}

    def _load_minimal_data(self, pair, hours=24):
        """åŠ è½½æœ€å°‘çš„æ•°æ®"""
        conn = sqlite3.connect('aether_oracle.db')

        # åªè·å–æœ€è¿‘Nå°æ—¶çš„æ•°æ®
        query = """
        WITH recent_data AS (
            SELECT
                price,
                volume,
                timestamp,
                ROW_NUMBER() OVER (ORDER BY timestamp DESC) as rn
            FROM exchange_rates
            WHERE pair = ?
            ORDER BY timestamp DESC
            LIMIT ?
        )
        SELECT * FROM recent_data ORDER BY timestamp
        """

        # æ¯30ç§’ä¸€æ¡æ•°æ®ï¼Œ24å°æ—¶çº¦2880æ¡ï¼Œæˆ‘ä»¬åªå–500æ¡
        df = pd.read_sql_query(query, conn, params=(pair, 500))
        conn.close()

        if df.empty or len(df) < 100:
            return np.array([]), np.array([])

        # è¶…ç®€å•ç‰¹å¾ï¼ˆåªç”¨10ä¸ªæœ€é‡è¦çš„ï¼‰
        features = pd.DataFrame()

        # åŸºç¡€ç‰¹å¾
        features['price'] = df['price'].values
        features['volume'] = df['volume'].values
        features['returns'] = features['price'].pct_change().fillna(0)

        # ç®€å•ç§»åŠ¨å¹³å‡
        features['sma_5'] = features['price'].rolling(5, min_periods=1).mean()
        features['sma_10'] = features['price'].rolling(10, min_periods=1).mean()
        features['price_to_sma5'] = features['price'] / features['sma_5']

        # ç®€å•æ³¢åŠ¨ç‡
        features['volatility'] = features['returns'].rolling(5, min_periods=1).std()

        # æˆäº¤é‡ç‰¹å¾
        features['volume_sma'] = features['volume'].rolling(5, min_periods=1).mean()
        features['volume_ratio'] = features['volume'] / (features['volume_sma'] + 1e-10)

        # RSIï¼ˆè¶…ç®€åŒ–ç‰ˆï¼‰
        delta = features['price'].diff()
        gain = delta.where(delta > 0, 0).rolling(7, min_periods=1).mean()
        loss = -delta.where(delta < 0, 0).rolling(7, min_periods=1).mean()
        features['rsi'] = 100 - (100 / (1 + gain / (loss + 1e-10)))

        # å¡«å……ç¼ºå¤±å€¼
        features = features.fillna(0)

        # å‡†å¤‡è®­ç»ƒæ•°æ®ï¼ˆç®€å•æ»‘çª—ï¼‰
        lookback = 5  # åªçœ‹è¿‡å»5ä¸ªæ—¶é—´ç‚¹
        X = []
        y = []

        for i in range(lookback, len(features) - 1):
            X.append(features.iloc[i-lookback:i].values.flatten())
            y.append(features.iloc[i + 1]['price'])  # é¢„æµ‹ä¸‹ä¸€ä¸ªä»·æ ¼

        return np.array(X), np.array(y)

    def _save_fast_model(self, pair, model, r2, rmse):
        """å¿«é€Ÿä¿å­˜æ¨¡å‹"""
        pair_key = pair.replace('/', '_')

        # ä¿å­˜æ¨¡å‹
        model_path = os.path.join(self.model_dir, f'{pair_key}_lgb_model.txt')
        model.booster_.save_model(model_path)  # ä½¿ç”¨booster_

        # ä¿å­˜ç®€å•å…ƒæ•°æ®
        metadata = {
            'pair': pair,
            'trained_at': datetime.now().isoformat(),
            'version': 'super_fast_1.0',
            'performance': {
                'r2': float(r2),
                'rmse': float(rmse)
            },
            'training_config': {
                'data_points': 500,
                'features': 10,
                'lookback': 5
            }
        }

        metadata_path = os.path.join(self.model_dir, f'{pair_key}_metadata.json')
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)

        logger.info(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {model_path}")

def main():
    import argparse

    parser = argparse.ArgumentParser(description='è¶…çº§å¿«é€Ÿè®­ç»ƒ')
    parser.add_argument('--pair', type=str, default='ETH/USDT')
    parser.add_argument('--all', action='store_true', help='è®­ç»ƒæ‰€æœ‰ä¸»è¦å¸ç§')

    args = parser.parse_args()

    trainer = SuperFastTrainer()

    if args.all:
        pairs = ['ETH/USDT', 'BTC/USDT', 'BNB/USDT', 'SOL/USDT', 'ADA/USDT']
        total_time = 0

        for pair in pairs:
            logger.info(f"\nè®­ç»ƒ {pair}...")
            try:
                result = trainer.train_super_fast(pair)
                if result:
                    total_time += result['time']
            except Exception as e:
                logger.error(f"âŒ {pair} å¤±è´¥: {e}")

        logger.info(f"\nâœ… å…¨éƒ¨å®Œæˆï¼æ€»è€—æ—¶: {total_time:.1f}ç§’")
    else:
        trainer.train_super_fast(args.pair)

if __name__ == "__main__":
    main()