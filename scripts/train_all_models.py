"""
æ‰¹é‡è®­ç»ƒæ‰€æœ‰è´§å¸å¯¹çš„AIæ¨¡å‹
åœ¨æ•°æ®é‡‡é›†24å°æ—¶åè¿è¡Œæ­¤è„šæœ¬
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import sqlite3
import subprocess
import time
import logging
from datetime import datetime, timedelta

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('model_training.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger('ModelTrainer')

class BatchModelTrainer:
    def __init__(self):
        self.db_path = 'aether_oracle.db'
        self.model_dir = 'saved_models'
        self.min_records = 1000  # æœ€å°‘éœ€è¦1000æ¡è®°å½•æ‰è®­ç»ƒ
        self.training_results = {}

    def check_data_availability(self):
        """æ£€æŸ¥æ¯ä¸ªè´§å¸å¯¹çš„æ•°æ®å¯ç”¨æ€§"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute("""
            SELECT pair,
                   COUNT(*) as record_count,
                   MIN(timestamp) as earliest,
                   MAX(timestamp) as latest,
                   julianday(MAX(timestamp)) - julianday(MIN(timestamp)) as days_of_data
            FROM exchange_rates
            GROUP BY pair
            ORDER BY record_count DESC
        """)

        pairs_status = []
        for pair, count, earliest, latest, days in cursor.fetchall():
            status = {
                'pair': pair,
                'records': count,
                'days': days,
                'earliest': earliest,
                'latest': latest,
                'ready': count >= self.min_records
            }
            pairs_status.append(status)

        conn.close()
        return pairs_status

    def train_single_model(self, pair):
        """è®­ç»ƒå•ä¸ªæ¨¡å‹"""
        logger.info(f"\n{'='*50}")
        logger.info(f"å¼€å§‹è®­ç»ƒ {pair} æ¨¡å‹...")

        try:
            # æ„å»ºå‘½ä»¤
            cmd = [
                'python' if os.name == 'nt' else 'python3',
                'models/train_model_optimized.py',
                '--pair', pair,
                '--fast-mode'  # ä½¿ç”¨å¿«é€Ÿæ¨¡å¼
            ]

            # æ‰§è¡Œè®­ç»ƒ
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
            )

            if result.returncode == 0:
                logger.info(f"âœ… {pair} æ¨¡å‹è®­ç»ƒæˆåŠŸï¼")

                # è§£æè¾“å‡ºè·å–å‡†ç¡®ç‡
                output_lines = result.stdout.split('\n')
                for line in output_lines:
                    if 'R2 Score' in line or 'accuracy' in line.lower():
                        logger.info(f"  {line.strip()}")

                self.training_results[pair] = {
                    'status': 'success',
                    'message': 'è®­ç»ƒæˆåŠŸ',
                    'time': datetime.now().isoformat()
                }
                return True

            else:
                logger.error(f"âŒ {pair} æ¨¡å‹è®­ç»ƒå¤±è´¥")
                logger.error(f"é”™è¯¯ä¿¡æ¯: {result.stderr}")
                self.training_results[pair] = {
                    'status': 'failed',
                    'message': result.stderr[:200],
                    'time': datetime.now().isoformat()
                }
                return False

        except subprocess.TimeoutExpired:
            logger.error(f"âŒ {pair} è®­ç»ƒè¶…æ—¶")
            self.training_results[pair] = {
                'status': 'timeout',
                'message': 'è®­ç»ƒè¶…æ—¶ï¼ˆè¶…è¿‡5åˆ†é’Ÿï¼‰',
                'time': datetime.now().isoformat()
            }
            return False

        except Exception as e:
            logger.error(f"âŒ {pair} è®­ç»ƒå‡ºé”™: {e}")
            self.training_results[pair] = {
                'status': 'error',
                'message': str(e),
                'time': datetime.now().isoformat()
            }
            return False

    def train_all_models(self, force_retrain=False):
        """æ‰¹é‡è®­ç»ƒæ‰€æœ‰æ¨¡å‹"""
        logger.info("="*60)
        logger.info("ğŸš€ AetherPay AIæ¨¡å‹æ‰¹é‡è®­ç»ƒ")
        logger.info("="*60)

        # æ£€æŸ¥æ•°æ®å¯ç”¨æ€§
        logger.info("\nğŸ“Š æ£€æŸ¥æ•°æ®å¯ç”¨æ€§...")
        pairs_status = self.check_data_availability()

        # åˆ†ç±»
        ready_pairs = [p for p in pairs_status if p['ready']]
        not_ready_pairs = [p for p in pairs_status if not p['ready']]

        # æ˜¾ç¤ºç»Ÿè®¡
        logger.info(f"\nâœ… å¯è®­ç»ƒçš„è´§å¸å¯¹ ({len(ready_pairs)}):")
        for p in ready_pairs:
            logger.info(f"  - {p['pair']:12s}: {p['records']:6d} æ¡è®°å½•, {p['days']:.1f} å¤©æ•°æ®")

        if not_ready_pairs:
            logger.info(f"\nâš ï¸ æ•°æ®ä¸è¶³çš„è´§å¸å¯¹ ({len(not_ready_pairs)}):")
            for p in not_ready_pairs:
                logger.info(f"  - {p['pair']:12s}: {p['records']:6d} æ¡è®°å½• (éœ€è¦ {self.min_records} æ¡)")

        if not ready_pairs:
            logger.error("\nâŒ æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®å¯ä»¥è®­ç»ƒæ¨¡å‹ï¼")
            logger.info("è¯·ç»§ç»­è¿è¡Œæ•°æ®é‡‡é›†å™¨ï¼Œç­‰å¾…æ•°æ®ç§¯ç´¯ã€‚")
            return

        # ç¡®è®¤è®­ç»ƒ
        logger.info(f"\nå‡†å¤‡è®­ç»ƒ {len(ready_pairs)} ä¸ªæ¨¡å‹")
        if not force_retrain:
            response = input("ç¡®è®¤å¼€å§‹è®­ç»ƒ? (y/n): ")
            if response.lower() != 'y':
                logger.info("è®­ç»ƒå·²å–æ¶ˆ")
                return

        # å¼€å§‹è®­ç»ƒ
        logger.info("\nğŸ”§ å¼€å§‹æ‰¹é‡è®­ç»ƒ...")
        start_time = time.time()
        success_count = 0
        failed_count = 0

        # ä¼˜å…ˆè®­ç»ƒé‡è¦çš„è´§å¸å¯¹
        priority_pairs = ['BTC/USDT', 'ETH/USDT', 'USDC/USDT', 'CNY/USD', 'EUR/USD']

        # æŒ‰ä¼˜å…ˆçº§æ’åº
        ready_pairs.sort(key=lambda x: (
            0 if x['pair'] in priority_pairs else 1,
            priority_pairs.index(x['pair']) if x['pair'] in priority_pairs else 999
        ))

        for status in ready_pairs:
            pair = status['pair']

            # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ¨¡å‹
            model_file = f"{self.model_dir}/{pair.replace('/', '_')}_lgb_model.txt"
            if os.path.exists(model_file) and not force_retrain:
                logger.info(f"â­ï¸  {pair} æ¨¡å‹å·²å­˜åœ¨ï¼Œè·³è¿‡")
                continue

            if self.train_single_model(pair):
                success_count += 1
            else:
                failed_count += 1

            # é¿å…è¿‡è½½
            time.sleep(2)

        # è®­ç»ƒå®Œæˆ
        elapsed_time = time.time() - start_time
        logger.info("\n" + "="*60)
        logger.info("ğŸ“Š è®­ç»ƒå®Œæˆç»Ÿè®¡:")
        logger.info(f"  æˆåŠŸ: {success_count} ä¸ªæ¨¡å‹")
        logger.info(f"  å¤±è´¥: {failed_count} ä¸ªæ¨¡å‹")
        logger.info(f"  æ€»è€—æ—¶: {elapsed_time/60:.1f} åˆ†é’Ÿ")

        # ä¿å­˜è®­ç»ƒç»“æœ
        self.save_training_report()

        # éªŒè¯æ¨¡å‹æ–‡ä»¶
        self.verify_models()

    def verify_models(self):
        """éªŒè¯æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        logger.info("\nğŸ” éªŒè¯æ¨¡å‹æ–‡ä»¶...")

        model_files = []
        for file in os.listdir(self.model_dir):
            if file.endswith('_lgb_model.txt') or file.endswith('_model.onnx'):
                model_files.append(file)

        logger.info(f"æ‰¾åˆ° {len(model_files)} ä¸ªæ¨¡å‹æ–‡ä»¶:")
        for f in sorted(model_files):
            size = os.path.getsize(f"{self.model_dir}/{f}") / 1024  # KB
            logger.info(f"  âœ… {f:30s} ({size:.1f} KB)")

    def save_training_report(self):
        """ä¿å­˜è®­ç»ƒæŠ¥å‘Š"""
        import json

        report = {
            'training_time': datetime.now().isoformat(),
            'results': self.training_results
        }

        report_file = f"training_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2)

        logger.info(f"\nğŸ“„ è®­ç»ƒæŠ¥å‘Šå·²ä¿å­˜: {report_file}")

    def quick_train_essential(self):
        """å¿«é€Ÿè®­ç»ƒæœ€é‡è¦çš„æ¨¡å‹"""
        essential_pairs = ['BTC/USDT', 'ETH/USDT', 'USDC/USDT']

        logger.info("ğŸš€ å¿«é€Ÿè®­ç»ƒæ ¸å¿ƒæ¨¡å‹")
        logger.info(f"ç›®æ ‡: {', '.join(essential_pairs)}")

        for pair in essential_pairs:
            self.train_single_model(pair)

def main():
    import argparse

    parser = argparse.ArgumentParser(description='æ‰¹é‡è®­ç»ƒAIæ¨¡å‹')
    parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶é‡æ–°è®­ç»ƒå·²æœ‰æ¨¡å‹')
    parser.add_argument('--quick', action='store_true', help='åªè®­ç»ƒæ ¸å¿ƒæ¨¡å‹')
    args = parser.parse_args()

    trainer = BatchModelTrainer()

    if args.quick:
        trainer.quick_train_essential()
    else:
        trainer.train_all_models(force_retrain=args.force)

if __name__ == '__main__':
    main()